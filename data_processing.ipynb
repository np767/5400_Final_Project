{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93eef538",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016af49d",
   "metadata": {},
   "source": [
    "### Speech Type Decoding\n",
    "\n",
    "1: Partisan rallies\n",
    "\n",
    "2: Formal congressional floor speeches\n",
    "\n",
    "3: Bipartisan events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8adacf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required packages\n",
    "import os \n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_speeches_from_directory(base_dir=\"data\"):\n",
    "    data = []\n",
    "\n",
    "    # loop through each folder in base_dir\n",
    "    for person_folder in os.listdir(base_dir):\n",
    "        person_path = os.path.join(base_dir, person_folder)\n",
    "\n",
    "        if not os.path.isdir(person_path) or \"_\" not in person_folder:\n",
    "            continue\n",
    "\n",
    "        # loop through all text files\n",
    "        for filename in os.listdir(person_path):\n",
    "            if filename.startswith(\".\") or not filename.endswith(\".txt\"):\n",
    "                continue\n",
    "\n",
    "            # extract speech type\n",
    "            speech_type_str = filename.split(\"_\")[0]\n",
    "            try:\n",
    "                speech_type = int(speech_type_str)\n",
    "            except ValueError:\n",
    "                continue \n",
    "\n",
    "            file_path = os.path.join(person_path, filename)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "\n",
    "            data.append({\n",
    "                \"person\": person_folder,\n",
    "                \"speech_type\": speech_type,\n",
    "                \"text\": text\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6246b26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>speech_type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desantis_ron</td>\n",
       "      <td>1</td>\n",
       "      <td>CPAC.  Let me welcome you to the freest state ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>desantis_ron</td>\n",
       "      <td>1</td>\n",
       "      <td>Thank you. Thank you very much. Well, thank yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desantis_ron</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr. Speaker, Mr. President, members of the cab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desantis_ron</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Chief Justice, Senator and Mrs. Scott, mem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person  speech_type  \\\n",
       "0  desantis_ron            1   \n",
       "1  desantis_ron            1   \n",
       "2  desantis_ron            2   \n",
       "3  desantis_ron            3   \n",
       "\n",
       "                                                text  \n",
       "0  CPAC.  Let me welcome you to the freest state ...  \n",
       "1  Thank you. Thank you very much. Well, thank yo...  \n",
       "2  Mr. Speaker, Mr. President, members of the cab...  \n",
       "3  Mr. Chief Justice, Senator and Mrs. Scott, mem...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_speeches_from_directory(\"data\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f50fb",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4203d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\erina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text_simple(text):\n",
    "    # lowercase, remove punctuation, tokenize, and remove stopwords\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    # lemmatize\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f0e79d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>speech_type</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desantis_ron</td>\n",
       "      <td>1</td>\n",
       "      <td>CPAC.  Let me welcome you to the freest state ...</td>\n",
       "      <td>cpac let welcome freest state united state luc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>desantis_ron</td>\n",
       "      <td>1</td>\n",
       "      <td>Thank you. Thank you very much. Well, thank yo...</td>\n",
       "      <td>thank thank much well thank much past four yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desantis_ron</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr. Speaker, Mr. President, members of the cab...</td>\n",
       "      <td>mr speaker mr president member cabinet legisla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desantis_ron</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Chief Justice, Senator and Mrs. Scott, mem...</td>\n",
       "      <td>mr chief justice senator mr scott member cabin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person  speech_type  \\\n",
       "0  desantis_ron            1   \n",
       "1  desantis_ron            1   \n",
       "2  desantis_ron            2   \n",
       "3  desantis_ron            3   \n",
       "\n",
       "                                                text  \\\n",
       "0  CPAC.  Let me welcome you to the freest state ...   \n",
       "1  Thank you. Thank you very much. Well, thank yo...   \n",
       "2  Mr. Speaker, Mr. President, members of the cab...   \n",
       "3  Mr. Chief Justice, Senator and Mrs. Scott, mem...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  cpac let welcome freest state united state luc...  \n",
       "1  thank thank much well thank much past four yea...  \n",
       "2  mr speaker mr president member cabinet legisla...  \n",
       "3  mr chief justice senator mr scott member cabin...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the df\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text_simple)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da5423",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "\n",
    "- Linguistic feature analysis (ie. average sentence length, lexical diversity, pronoun use to capture shifts in formality or inclusivity, words used to conclude sentences)\n",
    "\n",
    "- Artificial neural network as implemented in the word2vec mode, including skip-gram and continuous bag-of-word mechanisms (Python’s Genism package)\n",
    "\n",
    "- Computational semantic space modeling to identify whether recurring themes differ depending on audience\n",
    "\n",
    "- TF-IDF analysis for each setting of speech by politician\n",
    "\n",
    "- Embedding-based analysis (similarity, distance based, vector spaces, plane spaces) to measure a politician’s semantic speech space\n",
    "\n",
    "- Clustering (Hierarchical clustering, GMM) or classification models (SVMs, Mixed-Effects Logistic Regression, Softmax Regression) trained on one setting (ie. partisan rallies) and tested on another (ie. formal congressional floor speeches) to evaluate speech style"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
